{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision #provide access to datasets, models, transforms, utils, etc\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 50\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_set = torchvision.datasets.MNIST(\n",
    "            root='./try1',\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=transforms.Compose([\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10,  4,  4,  ...,  6,  7, 10])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying the sum of 60000 random integers with labels of train dataset of mnist\n",
    "sum_labels = mnist_train_set.targets + torch.randint(0, 9, (1, 60000)).squeeze()\n",
    "sum_labels\n",
    "# torch.stack((mnist_train_set.targets, sum_labels), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(mnist_train_set))\n",
    "image, label = sample\n",
    "image.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist_train_set.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rn = torch.randint(0, 9, (1, 60000)).squeeze()\n",
    "rn[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting sum_labels into binary represatation tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3333, 0.0000, 0.3333, 0.3333, 0.0000])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_binary(num):\n",
    "    binary = torch.zeros((5,), dtype=torch.float32)\n",
    "    i = 0\n",
    "    while(num != 0):\n",
    "        if num % 2 == 1:\n",
    "            binary[i] = 1.0\n",
    "        num = num // 2\n",
    "        i +=1\n",
    "    ones = (binary == 1.0).sum(dim=0)\n",
    "    \n",
    "    if ones == 2:\n",
    "        binary /= 2.0\n",
    "    if ones == 3:\n",
    "        binary /= 3.0\n",
    "    if ones == 4:\n",
    "        binary /= 4.0\n",
    "\n",
    "    return binary\n",
    "\n",
    "to_binary(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTWithNumbers(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.mnist_data = torchvision.datasets.MNIST(\n",
    "            root='./data',\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=transforms.Compose([\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "        )\n",
    "\n",
    "        self.random_numbers = torch.randint(0, 9, (1, len(self.mnist_data.targets))).squeeze()\n",
    "        self.numbers = torch.zeros((len(self.mnist_data.targets), 10))\n",
    "        for i in range(len(self.mnist_data.targets)):\n",
    "            self.numbers[i][self.random_numbers[i]] = 1\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        sample = self.mnist_data[index]\n",
    "        image = sample[0].unsqueeze(0)\n",
    "        label = torch.tensor(sample[1])\n",
    "        number = self.numbers[index].unsqueeze(0)\n",
    "        sum_ = label + self.random_numbers[index]\n",
    "        sum_label = to_binary(sum_)\n",
    "        \n",
    "        return image, label, number, sum_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mnist_data.data)\n",
    "    \n",
    "    @property\n",
    "    def train_labels(self):\n",
    "        \n",
    "        sum_labels = self.mnist_data.targets + self.random_numbers\n",
    "        return self.mnist_data.targets, sum_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_with_numbers = MNISTWithNumbers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000]), torch.Size([60000]))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets, sum_labels = mnist_with_numbers.train_labels\n",
    "targets.shape, sum_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\3dsma\\AppData\\Local\\Temp\\ipykernel_4548\\2801394307.py:7: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  num = num // 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 28, 28]),\n",
       " torch.Size([]),\n",
       " torch.Size([1, 10]),\n",
       " torch.Size([5]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(mnist_with_numbers))\n",
    "image, label, number, sum_label = sample\n",
    "image.shape, label.shape, number.shape, sum_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " tensor([0.3333, 0.3333, 0.3333, 0.0000, 0.0000]),\n",
       " tensor(5))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number, sum_label, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    mnist_with_numbers,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\3dsma\\AppData\\Local\\Temp\\ipykernel_4548\\2801394307.py:7: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  num = num // 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 1, 28, 28]),\n",
       " torch.Size([32]),\n",
       " torch.Size([32, 1, 10]),\n",
       " torch.Size([32, 5]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_data_loader))\n",
    "images, labels, numbers, sum_labels = batch\n",
    "images.shape, labels.shape, numbers.shape, sum_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3) \n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(in_features=1600, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=130, out_features=60)\n",
    "        self.out1 = nn.Linear(in_features=60, out_features=10)\n",
    "        self.fc3 = nn.Linear(in_features=60, out_features=30)\n",
    "        self.out2 = nn.Linear(in_features=30, out_features=5)\n",
    "\n",
    "    def forward(self, t1, t2):\n",
    "        # input layer\n",
    "        x1 = t1\n",
    "        x2 = t2\n",
    "\n",
    "        # conv1 layer\n",
    "        x1 = self.conv1(x1) # 28 | 26\n",
    "        x1 = F.relu(x1)\n",
    "\n",
    "        # conv2 layer\n",
    "        x1 = self.conv2(x1) # 26 | 24\n",
    "        x1 = F.relu(x1)\n",
    "        x1 = F.max_pool2d(x1, kernel_size=2, stride=2) # 24 | 12\n",
    "        \n",
    "        # conv3 layer\n",
    "        x1 = self.conv3(x1) # 12 | 10\n",
    "        x1 = F.relu(x1)\n",
    "        x1 = F.max_pool2d(x1, kernel_size=2, stride=2) # 10 | 5\n",
    "\n",
    "        # flattening the tensor till dimension 1 and keeping the batches\n",
    "        x1 = x1.flatten(1) # 64 * 5 * 5 = 1600\n",
    "\n",
    "        # fc1 layer\n",
    "        x1 = self.fc1(x1) # 1600 | 120\n",
    "        x1 = F.relu(x1)\n",
    "\n",
    "        # concatenating the random number\n",
    "        x = torch.cat((x1, x2), 1) # 120 + 10 \n",
    "\n",
    "        # fc2 layer \n",
    "        x = self.fc2(x) # 130 | 60\n",
    "        x = F.relu(x)\n",
    "\n",
    "        #  out1 layer\n",
    "        out1 = self.out1(x) # 60 | 10\n",
    "        out1 = F.softmax(out1, dim=1)\n",
    "\n",
    "        # fc3 layer\n",
    "        out2 = self.fc3(x) # 60 | 30\n",
    "        out2 = F.relu(out2)\n",
    "\n",
    "        # out2 layer\n",
    "\n",
    "        out2 = self.out2(out2) # 30 | 5\n",
    "        out2 = F.softmax(out2, dim=1)\n",
    "\n",
    "        return out1, out2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0912, 0.0941, 0.1144, 0.1164, 0.0995, 0.0966, 0.0914, 0.1049, 0.0942,\n",
       "          0.0972]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.2105, 0.2029, 0.1753, 0.2212, 0.1901]], grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1, out2 = network(image, number)\n",
    "out1, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "48c2112a8328d33382c63d86ada5a19139318595a90575a431b9665a806e2427"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
