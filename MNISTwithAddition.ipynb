{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision #provide access to datasets, models, transforms, utils, etc\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1990, 0.2419, 0.1729, 0.2139, 0.1723], grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 0., 1., 0.], grad_fn=<SelectBackward0>),\n",
       " tensor([1., 1., 1., 0., 0.]),\n",
       " tensor(False))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_labels[sum_labels > 0] = 1\n",
    "sum_labels\n",
    "\n",
    "out1, out2 = network(images, numbers)\n",
    "n = sum_labels[0].eq(1.).sum().item()\n",
    "_, indices = torch.topk(out2[0], n)\n",
    "print(out2[0])\n",
    "out2[0][indices] = 1.\n",
    "out2[0][out2[0] < 1] = 0.\n",
    "out2[0], sum_labels[0], torch.all(out2[0].eq(sum_labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "def get_preds_sum_correct(preds, labels, batch_size):\n",
    "    count = 0\n",
    "    labels[labels > 0] = 1.\n",
    "    for i in range(batch_size):\n",
    "        n =  labels[i].eq(1.).sum().item()\n",
    "        if n > 0:\n",
    "            _, index = torch.topk(preds[i], n)\n",
    "            preds[i][index] = 1.\n",
    "    preds[preds<1] = 0.\n",
    "    for i in range(batch_size):\n",
    "        if torch.all(labels[i].eq(preds[i])):\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 9)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_preds_correct(out1, labels), get_preds_sum_correct(out2, sum_labels, 32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing if everything is working fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1: 2.301152229309082 1.583652377128601\n",
      "loss2: 2.300562858581543 1.5824871063232422\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "mnist_with_numbers = MNISTWithNumbers()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    mnist_with_numbers,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "network = Network()\n",
    "\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.001)\n",
    "\n",
    "batch = next(iter(train_loader)) #get batch\n",
    "images, labels, numbers, sum_labels = batch\n",
    "pred_labels, pred_sums = network(images, numbers)\n",
    "loss_image = F.cross_entropy(pred_labels, labels) # calculating loss for image\n",
    "loss_sum = F.cross_entropy(pred_sums, sum_labels) # calculating loss for sum\n",
    "\n",
    "loss_image.backward(retain_graph=True) #calculate gradients\n",
    "loss_sum.backward()\n",
    "optimizer.step() #update weights\n",
    "\n",
    "print('loss1:', loss_image.item(), loss_sum.item())\n",
    "pred_labels, pred_sums = network(images, numbers)\n",
    "loss_image = F.cross_entropy(pred_labels, labels) \n",
    "loss_sum = F.cross_entropy(pred_sums, sum_labels)\n",
    "print('loss2:',loss_image.item(), loss_sum.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 \n",
      " \t MNIST: total loss:  841.63 acc:  66.52 \n",
      " \t Addition: total loss:  716.23 acc:  30.84\n",
      "epoch: 1 \n",
      " \t MNIST: total loss:  742.74 acc:  87.79 \n",
      " \t Addition: total loss:  706.50 acc:  34.83\n",
      "epoch: 2 \n",
      " \t MNIST: total loss:  714.16 acc:  94.09 \n",
      " \t Addition: total loss:  666.46 acc:  43.20\n",
      "epoch: 3 \n",
      " \t MNIST: total loss:  693.29 acc:  98.48 \n",
      " \t Addition: total loss:  640.79 acc:  49.05\n",
      "epoch: 4 \n",
      " \t MNIST: total loss:  691.48 acc:  98.83 \n",
      " \t Addition: total loss:  633.88 acc:  50.19\n",
      "epoch: 5 \n",
      " \t MNIST: total loss:  690.57 acc:  98.96 \n",
      " \t Addition: total loss:  631.04 acc:  51.63\n",
      "epoch: 6 \n",
      " \t MNIST: total loss:  689.55 acc:  99.17 \n",
      " \t Addition: total loss:  628.63 acc:  54.28\n",
      "epoch: 7 \n",
      " \t MNIST: total loss:  688.89 acc:  99.29 \n",
      " \t Addition: total loss:  627.46 acc:  54.55\n",
      "epoch: 8 \n",
      " \t MNIST: total loss:  688.53 acc:  99.37 \n",
      " \t Addition: total loss:  626.80 acc:  56.18\n",
      "epoch: 9 \n",
      " \t MNIST: total loss:  688.17 acc:  99.43 \n",
      " \t Addition: total loss:  626.05 acc:  57.03\n",
      "epoch: 10 \n",
      " \t MNIST: total loss:  687.93 acc:  99.48 \n",
      " \t Addition: total loss:  625.39 acc:  58.13\n",
      "epoch: 11 \n",
      " \t MNIST: total loss:  687.58 acc:  99.56 \n",
      " \t Addition: total loss:  624.88 acc:  58.42\n",
      "epoch: 12 \n",
      " \t MNIST: total loss:  687.59 acc:  99.54 \n",
      " \t Addition: total loss:  624.77 acc:  58.55\n",
      "epoch: 13 \n",
      " \t MNIST: total loss:  687.40 acc:  99.59 \n",
      " \t Addition: total loss:  624.50 acc:  58.54\n",
      "epoch: 14 \n",
      " \t MNIST: total loss:  687.06 acc:  99.67 \n",
      " \t Addition: total loss:  623.30 acc:  58.62\n",
      "epoch: 15 \n",
      " \t MNIST: total loss:  686.86 acc:  99.71 \n",
      " \t Addition: total loss:  622.24 acc:  60.66\n",
      "epoch: 16 \n",
      " \t MNIST: total loss:  686.50 acc:  99.77 \n",
      " \t Addition: total loss:  621.23 acc:  62.18\n",
      "epoch: 17 \n",
      " \t MNIST: total loss:  686.77 acc:  99.72 \n",
      " \t Addition: total loss:  620.66 acc:  62.39\n",
      "epoch: 18 \n",
      " \t MNIST: total loss:  686.58 acc:  99.76 \n",
      " \t Addition: total loss:  620.01 acc:  62.52\n",
      "epoch: 19 \n",
      " \t MNIST: total loss:  686.44 acc:  99.78 \n",
      " \t Addition: total loss:  619.78 acc:  62.64\n"
     ]
    }
   ],
   "source": [
    "network = Network()\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.001)\n",
    "network.to(device)\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    \n",
    "    total_correct_MNIST = 0\n",
    "    total_correct_sum = 0\n",
    "    total_loss_MNIST = 0\n",
    "    total_loss_sum = 0\n",
    "    total_size = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        images, labels, numbers, sum_labels = batch\n",
    "        images, labels, numbers, sum_labels = images.to(device), labels.to(device), numbers.to(device), sum_labels.to(device)\n",
    "        pred_images, pred_sums = network(images, numbers)\n",
    "        loss_image = F.cross_entropy(pred_images, labels) # calculating loss for image\n",
    "        loss_sum = F.cross_entropy(pred_sums, sum_labels) # calculating loss for sum\n",
    "\n",
    "        optimizer.zero_grad() # set the grads to zero \n",
    "        loss_image.backward(retain_graph=True)\n",
    "        loss_sum.backward()\n",
    "        optimizer.step() # update weights\n",
    "\n",
    "        total_loss_MNIST += loss_image.item()\n",
    "        total_correct_MNIST += get_preds_correct(pred_images, labels)\n",
    "        total_loss_sum += loss_sum.item()\n",
    "        total_correct_sum += get_preds_sum_correct(pred_sums, sum_labels, len(sum_labels))\n",
    "        total_size += len(images)\n",
    "\n",
    "    print(f'epoch: {epoch} \\n \\t MNIST: total loss: {total_loss_MNIST: .2f} acc: {total_correct_MNIST/total_size*100: .2f} \\n \\t Addition: total loss: {total_loss_sum: .2f} acc: {total_correct_sum/total_size*100: .2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "48c2112a8328d33382c63d86ada5a19139318595a90575a431b9665a806e2427"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
